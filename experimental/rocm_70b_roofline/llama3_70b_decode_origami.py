#!/usr/bin/env python3
# EXPERIMENTAL CODE: NOT FOR OFFICIAL INFERENCEMAX
# GENERATED BY CLAUDE CODE
# VERY LIKELY THAT ANYTHING IN EXPERIMENTAL FOLDER IS WRONG
# ROOFLINE ANALYSIS USING AMD ORIGAMI

"""Analyze GEMM shapes for LLaMA 3 70B decode using AMD origami library."""

import argparse
import origami

# LLaMA 3 70B architecture parameters
HIDDEN_SIZE = 8192
INTERMEDIATE_SIZE = 28672  # FFN intermediate size (SwiGLU)
NUM_LAYERS = 80

# AMD GPU specs for roofline model
GPU_SPECS = {
    "MI300X": {
        "bw_gbps": 5300,  # GB/s HBM3 bandwidth
        "flops": 1300e12,  # FP16 Matrix Core FLOPS (1.3 PFLOPS)
        "device_id": 0,
    },
    "MI300A": {
        "bw_gbps": 5300,  # GB/s HBM3 bandwidth
        "flops": 1300e12,  # FP16 Matrix Core FLOPS (1.3 PFLOPS)
        "device_id": 0,
    },
}

# Batch sizes to sweep
BATCH_SIZES = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]

# Matrix instruction configurations for gfx950 (MI300 series)
MatInst = {
    "f16": [
        (16, 16, 32, 1),  # gfx950
        (32, 32, 16, 1),  # gfx950
    ],
    "bf16": [
        (16, 16, 32, 1),  # gfx950
        (32, 32, 16, 1),  # gfx950
    ],
}


def createTileList(gemmType: str):
    """Create tile list for GEMM configurations."""
    LIST_OF_WAVEs_TO_INCLUDE = [[4, 1], [2, 2], [1, 4], [1, 2], [2, 1], [1, 1]]
    MIN_MT0 = MIN_MT1 = 16
    MAX_MT0 = MAX_MT1 = 512

    bm_max = 0
    tile_list = set()
    for MI in MatInst[gemmType]:
        for bm in range(bm_max + 1):
            MIBlockM = 2**bm

            for wave in LIST_OF_WAVEs_TO_INCLUDE:
                waveTileM = 0
                waveTileN = 0

                while True:
                    waveTileM += 1
                    waveTileN = 0
                    MatrixInstM = MI[0] * MIBlockM
                    MT0 = MatrixInstM * waveTileM * wave[0]
                    if MT0 < MIN_MT0:
                        continue
                    if MT0 > MAX_MT0:
                        break

                    while True:
                        waveTileN += 1
                        MatrixInstN = MI[1] / MIBlockM * MI[3]
                        MT1 = int(MatrixInstN * waveTileN * wave[1])

                        if MT1 < MIN_MT1:
                            continue
                        if MT1 > MAX_MT1:
                            break

                        # LDS size check for LSU
                        LSU = max(1, 4 // wave[0] // wave[1])
                        if LSU > 1 and MT0 * MT1 * 4 * LSU > 256 * 256:
                            continue

                        if MT0 * MT1 > 256 * 256:
                            continue
                        for DU in [16, 32, 64, 128, 256, 512, 1024]:
                            tile_list.add((MT0, MT1, DU, MI[0], MI[1], MI[2], 1, 6, 0, 0))

    return [tile for tile in tile_list]


def compute_roofline_sol(m: int, k: int, n: int, gpu_name: str):
    """Compute roofline Speed-of-Light (SOL) runtime for a GEMM operation.

    Args:
        m, k, n: GEMM dimensions (M x K) @ (K x N)
        gpu_name: GPU name for specs lookup

    Returns:
        Tuple of (runtime_ms, bytes_transferred, flops, is_memory_bound)
    """
    specs = GPU_SPECS[gpu_name]
    bw_bytes_per_s = specs["bw_gbps"] * 1e9  # Convert GB/s to B/s
    peak_flops = specs["flops"]

    # Bytes: read A (M*K) + read B (K*N) + write C (M*N), all in FP16 (2 bytes)
    bytes_transferred = 2 * (m * k + k * n + m * n)

    # FLOPs: 2*M*N*K for matmul
    flops = 2 * m * n * k

    # Time to transfer all data at peak bandwidth
    time_memory_s = bytes_transferred / bw_bytes_per_s

    # Time to compute all FLOPs at peak throughput
    time_compute_s = flops / peak_flops

    # Roofline: runtime is max of memory time and compute time
    is_memory_bound = time_memory_s >= time_compute_s
    runtime_s = max(time_memory_s, time_compute_s)
    runtime_ms = runtime_s * 1000.0

    return runtime_ms, bytes_transferred, flops, is_memory_bound


def compute_gemm_metrics(m: int, k: int, n: int, runtime_ms: float, gpu_name: str):
    """Compute MBU and MFU for a GEMM operation.

    Args:
        m, k, n: GEMM dimensions (M x K) @ (K x N)
        runtime_ms: Runtime in milliseconds
        gpu_name: GPU name for specs lookup

    Returns:
        Tuple of (bytes_transferred, flops, mbu_percent, mfu_percent)
    """
    specs = GPU_SPECS[gpu_name]
    bw_gbps = specs["bw_gbps"]
    peak_flops = specs["flops"]

    # Bytes: read A (M*K) + read B (K*N) + write C (M*N), all in FP16 (2 bytes)
    bytes_transferred = 2 * (m * k + k * n + m * n)

    # FLOPs: 2*M*N*K for matmul
    flops = 2 * m * n * k

    runtime_s = runtime_ms / 1000.0

    # Achieved bandwidth and compute
    achieved_bw_gbps = (bytes_transferred / 1e9) / runtime_s if runtime_s > 0 else 0
    achieved_flops = flops / runtime_s if runtime_s > 0 else 0

    # MBU and MFU as percentages
    mbu = (achieved_bw_gbps / bw_gbps) * 100
    mfu = (achieved_flops / peak_flops) * 100

    return bytes_transferred, flops, mbu, mfu


def estimate_origami_runtime(hardware, tile_list, m: int, k: int, n: int, trans_a: bool, trans_b: bool) -> tuple:
    """Estimate GEMM runtime using origami library.

    Returns:
        Tuple of (runtime_cycles, best_config)
    """
    ret = origami.select_best_macro_tile_size(
        m,
        n,
        k,
        1,  # batch size
        trans_a,
        trans_b,
        hardware,
        tile_list,
        origami.datatype_to_bits(origami.Half),  # bits_a
        origami.datatype_to_bits(origami.Half),  # bits_b
        origami.datatype_to_bits(origami.Half),  # bits_d
        origami.Half,  # dtype_a
        0,  # scale_block_size
        0.8,  # threshold
        False,  # print debug info
        6,  # wgm
    )

    # ret[0] contains: (latency, MT0, MT1, DU, MI0, MI1, MI2, MI3)
    latency_cycles = ret[0][0]
    best_config = ret[0][1:]

    return latency_cycles, best_config


def cycles_to_ms(cycles: float, clock_ghz: float) -> float:
    """Convert cycles to milliseconds."""
    return cycles / (clock_ghz * 1e9) * 1000.0


def print_gemm_shapes(gpu_name: str, device_id: int = 0) -> None:
    """Print all GEMM shapes for LLaMA 3 70B decode step across batch sizes."""
    seq_len = 1  # Decode generates one token at a time
    specs = GPU_SPECS[gpu_name]

    print("LLaMA 3 70B Decode FFN GEMM Shapes (AMD Origami Analysis)")
    print("=" * 180)
    print(f"Hidden size: {HIDDEN_SIZE}")
    print(f"Intermediate size: {INTERMEDIATE_SIZE}")
    print(f"GPU: {gpu_name} (BW: {specs['bw_gbps']} GB/s, FLOPS: {specs['flops']/1e12:.0f} TFLOPS)")
    print(f"Batch sizes: {BATCH_SIZES}")
    print("=" * 180)
    print()

    # Get hardware information
    hardware = origami.get_hardware_for_device(device_id)
    clock_ghz = hardware.compute_clock_ghz

    # Create tile list
    tile_list = createTileList("f16")
    print(f"Generated {len(tile_list)} tile configurations")
    print()

    for batch_size in BATCH_SIZES:
        m = batch_size * seq_len

        print(f"Batch size: {batch_size} (M={m})")
        print("-" * 180)
        print(
            f"  {'Name':20} {'Shape':>21}  {'Roofline':>10}  {'Origami':>10}  "
            f"{'MBU(R)':>7}  {'MFU(R)':>7}  {'MBU(O)':>7}  {'MFU(O)':>7}  {'Best Config':>30}"
        )
        print("-" * 180)

        gemms = [
            ("Gate Projection", (m, HIDDEN_SIZE, INTERMEDIATE_SIZE), True, False),
            ("Up Projection", (m, HIDDEN_SIZE, INTERMEDIATE_SIZE), True, False),
            ("Down Projection", (m, INTERMEDIATE_SIZE, HIDDEN_SIZE), True, False),
        ]

        total_roof_runtime = 0.0
        total_origami_runtime = 0.0
        total_bytes = 0
        total_flops = 0

        for name, (m_dim, k, n), trans_a, trans_b in gemms:
            # Roofline SOL
            roof_runtime, bytes_xfer, flops, is_mem_bound = compute_roofline_sol(m_dim, k, n, gpu_name)

            # Origami estimate
            origami_cycles, best_config = estimate_origami_runtime(hardware, tile_list, m_dim, k, n, trans_a, trans_b)
            origami_runtime = cycles_to_ms(origami_cycles, clock_ghz)

            # Compute metrics
            _, _, mbu_r, mfu_r = compute_gemm_metrics(m_dim, k, n, roof_runtime, gpu_name)
            _, _, mbu_o, mfu_o = compute_gemm_metrics(m_dim, k, n, origami_runtime, gpu_name)

            total_roof_runtime += roof_runtime
            total_origami_runtime += origami_runtime
            total_bytes += bytes_xfer
            total_flops += flops

            config_str = f"MT=({best_config[0]},{best_config[1]},{best_config[2]})"

            print(
                f"  {name:20} {m_dim:5} x {k:5} x {n:5}  {roof_runtime:8.4f} ms  {origami_runtime:8.4f} ms  "
                f"{mbu_r:6.2f}%  {mfu_r:6.2f}%  {mbu_o:6.2f}%  {mfu_o:6.2f}%  {config_str:>30}"
            )

        # Compute total MBU/MFU
        total_roof_s = total_roof_runtime / 1000.0
        total_roof_bw = (total_bytes / 1e9) / total_roof_s if total_roof_s > 0 else 0
        total_roof_flops = total_flops / total_roof_s if total_roof_s > 0 else 0
        total_mbu_r = (total_roof_bw / specs["bw_gbps"]) * 100
        total_mfu_r = (total_roof_flops / specs["flops"]) * 100

        total_origami_s = total_origami_runtime / 1000.0
        total_origami_bw = (total_bytes / 1e9) / total_origami_s if total_origami_s > 0 else 0
        total_origami_flops = total_flops / total_origami_s if total_origami_s > 0 else 0
        total_mbu_o = (total_origami_bw / specs["bw_gbps"]) * 100
        total_mfu_o = (total_origami_flops / specs["flops"]) * 100

        print("-" * 180)
        print(
            f"  {'Total per layer':20} {' ':>21}  {total_roof_runtime:8.4f} ms  {total_origami_runtime:8.4f} ms  "
            f"{total_mbu_r:6.2f}%  {total_mfu_r:6.2f}%  {total_mbu_o:6.2f}%  {total_mfu_o:6.2f}%"
        )
        print()


def main():
    parser = argparse.ArgumentParser(
        description="Analyze GEMM shapes for LLaMA 3 70B decode using AMD origami"
    )
    parser.add_argument(
        "--gpu",
        type=str,
        choices=list(GPU_SPECS.keys()),
        default="MI300X",
        help="GPU type (default: MI300X)",
    )
    parser.add_argument(
        "--device",
        type=int,
        default=0,
        help="GPU device ID (default: 0)",
    )
    args = parser.parse_args()

    print_gemm_shapes(args.gpu, args.device)


if __name__ == "__main__":
    main()
